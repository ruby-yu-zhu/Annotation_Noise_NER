### use # to comment out the configure item

################ Status ################
mode=test
# string: train/test/interactive_predict/api_service

################ Datasets(Input/Output) ################
datasets_fold=data
train_file=CONLL2003_train_datas.xlsx
test_file=combain_CONLL2003_testb_datas_with_ids1120.xlsx
output_test_file=combain_CONLL2003_mention_testb_results_with_ids_output1120.xlsx
# test.csv is file_name of test datas,you can change to your own filename

delimiter=b
# string: (t: "\t";"table")|(b: "backspace";" ")|(other, e.g., '|||', ...)

use_pretrained_embedding=False
token_emb_dir=data/glove.6B.300d.txt

vocabs_dir=data/vocabs

log_dir=data/logs

checkpoints_dir=checkpoints/BILSTM-CRFs

################ Labeling Scheme ################
label=[LOC,PER,ORG,MISC]
################ Model Configuration ################
cell_type=LSTM
# LSTM, GRU
biderectional=True
encoder_layers=1

embedding_dim=1024

hidden_dim=200

max_sequence_length=25
#int, cautions! set as a LARGE number as possible,
# this will be kept during training and inferring, text having length larger than this will be truncated.

max_char_len=50
char_dim=400
char_lstm_dim=400

use_self_attention=True
attention_dim=400
# unnecessary if use_self_attention=False

CUDA_VISIBLE_DEVICES=0
# coincides with tf.CUDA_VISIBLE_DEVICES

seed=42

################ Training Settings ###
epoch=50
batch_size=32

dropout=0.5
learning_rate=0.001

optimizer=Adam
#string: GD/Adagrad/AdaDelta/RMSprop/Adam

checkpoints_max_to_keep=3
print_per_batch=20

is_early_stop=False
patient=40
# unnecessary if is_early_stop=False
measuring_metrics=[precision,recall,f1,accuracy]

checkpoint_name=model

################ Testing Settings ###

################ Api service Settings ###

ip=0.0.0.0
port=8000
# unnecessary to change if keep these as default.
# unnecessary to add not at api_service mode.
